using Nemerle;
using Nemerle.Compiler;
using Nemerle.Collections;
using Nemerle.Compiler.Parsetree;
using Nemerle.Surround;
using Nemerle.Utility;

using System;
using SCG = System.Collections.Generic;

namespace Nemerle.Compiler
{
  
  class PreParserException : System.Exception
  {
    [Accessor]
    public mutable _location : Location;

    public this (location : Location, msg : string) {
      base (msg);
      _location = location;
    }
  }
  
  /// <summary>
  /// Base class for all PreParsers.
  /// </summary>
  public abstract class PreParserBase
  {
      
    // State
    protected lexer: LexerBase;
    protected mutable Env: GlobalEnv;
    protected mutable finished: bool = false;
    protected mutable last_declaration_token : Token = null;
    
    /** Parent stream is the stack of processed token nodes,
        which are already assigned to be in currently build sequence.
        For example:
          a; b; c (); d e _we_are_here_
        'a, b, c()', are alredy known to be in parent sequence,
        while 'd e' are in current temporary sequence, which might
        get added to parent_stream if separator (e.g. ';') occurs
    */
    protected parent_stream : SCG.List [Token] = SCG.List (100);

    /** Currently builded stream of token nodes is an array of
        loose tokens, which have occured after last separator.
        It will probably form LooseGroup as an element of parent
        sequence or all elements will constitue parent
    */
    protected current_stream : SCG.List [Token] = SCG.List (50);
    
    // Constructors
    protected this(lex: LexerBase) 
    {
        this(lex, lex.Manager.CoreEnv)
    }
        
    protected this(lex: LexerBase, env: GlobalEnv) 
    {
        lexer = lex;        
        Env = env;
        lexer.Keywords = Env.Keywords;
    }
    
    // Implementation Functions   
    public ParseTopLevel () : Token.BracesGroup {
      try {
        def stream = ParseTopLevelImpl ();
        Token.BracesGroup (if (stream != null) stream.Location else Location.Default, stream, null, null, true)
      } catch {
        | _ is LexerBase.PragmaIndent =>
          indention_based_copy ().ParseTopLevel ()
        | _ is LexerBase.PragmaImplicit =>
          implicit_based_copy ().ParseTopLevel ()          
      }
    }
    
    [Nemerle.Assertions.Ensures (value != null)]
    public PreParse () : Token.BracesGroup {
      try {
        def top = parse_brace_group (lexer.Location, null, false, true);
        unless (finished)
          Message.Error (lexer.Location, "expected end of file, encountered closing brace");
        top
      } catch {
        | _ is LexerBase.PragmaIndent =>
          indention_based_copy ().PreParse ()
        | _ is LexerBase.PragmaImplicit =>
          implicit_based_copy ().PreParse ()
      }
    }    
    
    indention_based_copy () : PreParserBase
    { 
      def copy = PreParserIndent (lexer);
      token_stack.Iter(copy.token_stack.Push(_));
      copy.Env = Env;
      copy.finished = finished;
      copy
    }    

    implicit_based_copy () : PreParserBase
    {      
      def copy = PreParserImplicit (lexer);
      token_stack.Iter(copy.token_stack.Push(_));
      copy.Env = Env;
      copy.finished = finished;
      copy
    }    

    
    // Virtual (Can Override) functions    
    protected virtual parse_brace_group (loc : Location, openBrace : Token.BeginBrace, expect_endbrace : bool, generated : bool) : Token.BracesGroup
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;

      reset_comment (loc);
      
      def loop ()
      {
        def tok = get_token ();
        unless(ReferenceEquals(Env.Defines, lexer.Defines))
          Env = Env.SetDefines(lexer.Defines);
        match (tok)
        {          
          // finish entire brace group
          | Token.EndBrace as closeBrace =>
            reset_comment(tok);
            def brace_group = finish_parent(parent_begin, current_begin);
            Token.BracesGroup(loc + tok.Location, brace_group, openBrace, closeBrace, generated);

          // finish current loose group
          | Token.Semicolon =>
            reset_comment(tok);
            finish_current(current_begin, tok);
            loop()

          | Token.EndOfFile when !expect_endbrace =>
            def brace_group = finish_parent (parent_begin, current_begin);
            finished = true;
            Token.BracesGroup (loc + tok.Location, brace_group, openBrace, null, generated);
            
          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () }
      catch { e is PreParserException =>
        Message.Error (loc, "when parsing this `{' brace group");
        Message.Error (e.Location, e.Message);
        def group = finish_parent (parent_begin, current_begin);
        Token.BracesGroup (shift_end(loc + e.Location), group, openBrace, null, generated);
      }
    }
   
    protected virtual ParseTopLevelImpl (nesting : int = 0) : Token
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;
      mutable currentNsEnv = Env; // GlobalEnv of current namespace

      def get_qualified_identifier () : list [string] * list [Location]
      {
        def tok1 = get_token ();
        match (tok1)
        {
          | Token.Identifier (x) =>
            def tok2 = get_token ();
            match (tok2)
            {
              | Token.Operator (".") =>
                def (ident, locs) = get_qualified_identifier ();
                match (ident)
                {
                  | [] => ([x], [tok1.Location, tok2.Location])
                  | _  => (x :: ident, tok1.Location :: tok2.Location :: locs)
                }
              | t => push_back (t); ([x], [tok1.Location])
            }
          | t =>
            Message.Error (t.Location, $"expected qualified identifier, got token $t");
            push_back (t);
            ([], [])
        }
      }

      def get_qualified_tokens () : list [string] * list [Location] * list[Token]
      {
        def tok1 = get_token ();
        match (tok1)
        {
          | Token.Identifier (x) =>
            def tok2 = get_token ();
            match (tok2)
            {
              | Token.Operator (".") =>
                def (ident, locs, toks) = get_qualified_tokens ();
                match (ident)
                {
                  | [] => ([x], [tok1.Location, tok2.Location], [tok1, tok2])
                  | _  => (x :: ident, tok1.Location :: tok2.Location :: locs, tok1 :: tok2 :: toks)
                }
              | t => push_back (t); ([x], [tok1.Location], [tok1])
            }
          | t =>
            Message.Error (t.Location, $"expected qualified identifier, got token $t");
            push_back (t);
            ([], [], [])
        }
      }

      def make_before_location (location)
      {
        Location(location.FileIndex, location.Line, location.Column);
      }

      def parse_using_directive (tok)
      {
        finish_current (current_begin);
        def (id, idLocs, idToks) = get_qualified_tokens ();

        mutable tokens_in_body = idToks;

        def create_body_token()
        {
          def body = tokens_in_body.Rev();
          mutable next = body.Tail;
          mutable loc = body.Head.Location;

          body.Iter(current =>
            {
              current.Next = match (next) { | [] => null | _ => next.Head };
              unless (next == []) next = next.Tail;
              loc += current.Location;
            });
          Token.LooseGroup(loc, body.Head);
        }

        match (get_token ()) {
          | Token.Semicolon as st =>
            def loc = tok.Location + st.Location;
            Env = Env.AddOpenNamespace (id, loc);
            lexer.Keywords = Env.Keywords;

            def using_tok = Token.Using (loc, Env, tok, create_body_token());
            current_stream.Add (using_tok);

            lexer.OnAfterUsingDirectiveParse(loc
              + make_before_location (st.Location), id, idLocs,
              "", Location.Default, currentNsEnv, Env);

          | Token.Operator ("=") as eq =>
            def (id2, idLocs2, idToks2) = get_qualified_tokens ();

            tokens_in_body = (eq :: tokens_in_body).Append(idToks2);

            def st = get_token ();
            def ty =
              match (st)
              {
                | Token.Semicolon => null
                | Token.BeginSquare => parseTypeName(idToks2, st)
                | _ =>
                  push_back (st);
                  Message.Error(st.Location, "expecting `;' after using alias");
                  null
              };

            match (id)
            {
              | [name] when ty == null =>
                Env = Env.AddNamespaceAlias (name, id2, tok.Location);
                lexer.OnAfterUsingDirectiveParse(tok.Location
                  + make_before_location (st.Location), id2, idLocs2,
                  name, idLocs.Head, currentNsEnv, Env);
                assert(idLocs.Length == 1);

              | [_name] => ()
                // make generic type alias...

              | [] => // occur if syntax error
                lexer.OnAfterUsingDirectiveParse(tok.Location
                  + make_before_location (st.Location), id2, idLocs2,
                  "", Location.Default, currentNsEnv, Env);

              | _ =>
                Message.Error (tok.Location, "using alias must be simple name without dots");
                lexer.OnAfterUsingDirectiveParse(tok.Location
                  + make_before_location (st.Location), id2, idLocs2,
                  id.ToString(), idLocs.Head + idLocs.Last, currentNsEnv, Env);
            }

            def using_tok = Token.Using (tok.Location + st.Location, Env, tok, create_body_token());
            current_stream.Add (using_tok);

          | x =>
            push_back (x);
            // The error message must point to last using token
            def loc1 = match (idLocs) { | [] => tok.Location | _ => idLocs.Last };
            def loc2 = Location(loc1.FileIndex, loc1.EndLine, loc1.EndColumn);
            Message.Error (loc2, "expecting `;' or `='");
            // In notification location must point before first token of next directive
            lexer.OnAfterUsingDirectiveParse(tok.Location + x.Location.FromStart(),
              id, idLocs, "", Location.Default, currentNsEnv, Env);
        }

        finish_current (current_begin);
      }

      def loop ()
      {
        def tok = get_token ();
        unless(ReferenceEquals(Env.Defines, lexer.Defines))
          Env = Env.SetDefines(lexer.Defines);
        match (tok)
        {
          | Token.Keyword ("using") => parse_using_directive (tok); loop ()

          | Token.Keyword ("namespace") =>
            finish_current (current_begin);

            def prevNsEnv = currentNsEnv;
            currentNsEnv = Env;

            def (id, idLocs) = get_qualified_identifier ();
            def headerLocation = if (idLocs.IsEmpty) tok.Location else tok.Location + idLocs.Last;

            match (get_token ())
            {
              | Token.BeginBrace as br =>
                last_declaration_token = null;

                def beginLoc = tok.Location + br.Location;
                def oldEnv   = Env;
                Env = Env.EnterIntoNamespace (id);
                lexer.Keywords = Env.Keywords;

                lexer.OnBeforeNamespaceParse();

                def decls = ParseTopLevelImpl(nesting + 1);

                // make location of namespace body
                def endLoc =
                  if (last_declaration_token is null)
                    Location.Default
                  else
                  {
                    def end = last_declaration_token.Location;
                    last_declaration_token = null;
                    end
                  };

                def namespace_tok = Token.Namespace(beginLoc + endLoc, Env, tok, decls);

                lexer.OnAfterNamespaceParse(namespace_tok.Location,
                  id, idLocs, oldEnv, Env, headerLocation, br.Location, endLoc);

                Env = oldEnv;
                lexer.Keywords = Env.Keywords;

                current_stream.Add (namespace_tok);

              | x => Message.Error (x.Location, "expecting `{' opening namespace scope")
            }
            finish_current (current_begin);
            currentNsEnv = prevNsEnv;
            loop ()

          // finish entire brace group
          | Token.EndBrace when nesting > 0 =>
            last_declaration_token = tok;
            reset_comment (tok);
            finish_parent (parent_begin, current_begin);

          // finish current loose group
          | Token.Semicolon => finish_current (current_begin, tok); loop ()

          | Token.EndOfFile when parent_begin == 0 =>
            // check #region/#endregion completion
            match (lexer.IncompleteRegions)
            {
              | h :: _ => Message.Error (h.Location, "#endregion directive expected")
              | [] => ()
            }

            def brace_group = finish_parent (parent_begin, current_begin);
            finished = true;
            last_declaration_token = tok;
            brace_group;

          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () }
      catch { e is PreParserException =>
        Message.Error (e.Location, e.Message);
        finish_parent (parent_begin, current_begin);
      }
    }
    
    // Abstract (Must Override) functions    
    protected abstract get_token() : Token;
   
    protected abstract handle_default_token (current_begin : int, tok : Token, braces_cut_current = true, scan_ahead_for_replacements = true) : void;
    
    
    #region Buffer
    
    protected token_stack : Stack[Token] = Stack(10);
    
    protected peek_token() : Token
    {
        def tok = get_token();
        push_back(tok);
        tok
    }
    
    protected push_back(tok: Token) : void
    {
        token_stack.Push(tok)
    }
    
    protected pop_next() : Token
    {
        token_stack.Pop()
    }
    
    protected stack_populated() : bool
    {
        token_stack.Length > 0
    }
    
    #endregion
    
    #region Comments
    
    [Nemerle.Utility.Accessor (flags = WantSetter | Internal)]
    protected mutable doc_comments : Map [Location, string];
    
    protected reset_comment (tok : Token) : void {
      when (doc_comments != null) doc_comments = doc_comments.Replace (tok.Location, "");
    }
    
    protected reset_comment (loc : Location) : void {
      when (doc_comments != null) doc_comments = doc_comments.Replace (loc, "");
    }
    
    #endregion
    
    #region Section Finshers
    
    /** Closes both currently created LooseGroup and parent group.
        Returns list of tokens composing parent group 
    */
    protected finish_parent (parent_begin : int, current_begin : int) : Token {
      finish_current (current_begin);
      def parent_group =
        if (parent_begin == parent_stream.Count)
          null // case of `(` `)`
        else
          make_list (parent_stream, parent_begin);
      parent_stream.RemoveRange (parent_begin, parent_stream.Count - parent_begin);
      parent_group
    }


    /** Closes currently created LooseGroup and adds it at the end of the
        parent group. After that we are ready to make another LooseGroup.

        It is called mainly when separator token occurs.
     */
    protected finish_current (current_begin : int, separator_token : Token = null) : void
    {
      if (current_begin == current_stream.Count)
        when (separator_token != null && !(separator_token is Token.Semicolon))
        {
          def loose = Token.LooseGroup (separator_token.Location, separator_token);
          parent_stream.Add (loose);
        }
      else
      {
        def loose_group = make_list (current_stream, current_begin);
        def location    = if (separator_token != null)
                            loose_group.Location + separator_token.Location.FromStart();
                          else
                            list_location (current_stream, current_begin);
        def loose       = Token.LooseGroup(location, loose_group, separator_token);

        parent_stream.Add (loose);
        current_stream.RemoveRange (current_begin, current_stream.Count - current_begin);
      }
    }   
    
    #endregion
    
    #region Static Helper Functions
      
    protected static shift_end(loc : Location) : Location
    {
      if (loc.EndColumn > 1)
        Location(loc.FileIndex, loc.Line, loc.Column, loc.EndLine, loc.EndColumn - 1);
      else
        loc
    }
    
    protected static parseTypeName(_idToks2 : list[Token], _brace : Token) : FixedType
    {
      null
    }
    
    /** links Tokens from specified subarray to form a list and return its head */
    protected static make_list (tokens : SCG.List [Token], start : int) : Token
    {
      for (mutable i = tokens.Count - 2; i >= start; --i)
        tokens [i].Next = tokens [i + 1];
      tokens [start]
    }

    /** returns a combined location of the subarray inside a token list */
    protected static list_location ( tokens : SCG.List [Token], start : int) : Location
    {
      assert(tokens.Count > 0);
      assert(start < tokens.Count);
      tokens [start].Location + tokens [tokens.Count - 1].Location
    }

    protected static get_token_type(tok: Token) : string {
      if (tok != null) {
           def tokStr = "[" + tok.GetType().Name + "]: " + tok.ToString();
           tokStr
      } else "{Unknown}"
    }
    
    public static Dump (tok : Token, ident : string) : string
    {
      def (open, close, sepstr, elements) =
        match (tok) {
          | Token.RoundGroup => ("(", ")", ", ", tok)
          | Token.BracesGroup => ("{\n" + ident, "}", ";\n" + ident, tok)
          | Token.SquareGroup => ("[", "]", ", ", tok)
          | Token.QuoteGroup  => ("<[\n", "]>", "; ", tok)
          | Token.LooseGroup  => ("", "", " ", tok)

          | _ => ("", tok.ToString (false), "", null)
        }

      $"$open..$(elements; sepstr)$close"
    }    
    
    #endregion
    
  }
}
